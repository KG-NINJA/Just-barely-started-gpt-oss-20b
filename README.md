# ğŸ§  Local 20B LLM Boot â€” On the Edge of Capacity

This repository documents a rare, high-risk attempt to locally run a **20B parameter language model (gpt-oss:20b)**  
on a mid-spec **Panasonic Let's Note** laptop â€” fully offline, with almost no free RAM or SSD space.

---
---

## ğŸ¥ Boot Attempt Recording

This short video captures the moment I attempted to run `gpt-oss:20b`  
under extreme conditions:  
- 92% RAM usage  
- Less than 5GB SSD free  
- No Wi-Fi  
- i5 CPU with integrated GPU

<video src="girigiriOSSkido.mp4" controls width="600">
  Your browser does not support the video tag.
</video>

ğŸ”— [Click here to download or view the video directly](./girigiriOSSkido.mp4)

---

## ğŸ§© The Machine â€” Panasonic Let's Note CF-SV

| Spec           | Value                          |
|----------------|---------------------------------|
| Model          | **Panasonic Let's Note CF-SV** |
| Processor      | Intel(R) Core(TM) i5-10310U CPU @ 1.70GHz (Turbo: 2.21GHz) |
| RAM            | 16.0 GB (15.7 GB usable)        |
| Graphics       | Integrated Intel UHD (128MB)    |
| Storage        | 236GB SSD (with <5GB free at test time) |
| OS             | Windows 11 Pro                 |
| Wi-Fi Status   | **OFF (Air-gapped)**           |
| Made in        | **ğŸ‡¯ğŸ‡µ JAPAN**                   |

ğŸ›¡ï¸ Known for durability, portability, and business-class resilience.  
But today, it proved capable of far more â€” running a **20B LLM under impossible conditions.**

> "**Not built for this... but still did it.**"

## ğŸ” Offline Proof

This was a **true local execution**.  
The system was completely disconnected from the internet at the time of model launch:

### ğŸ”’ No Wi-Fi  
![Wi-Fi off](wifioff.png)

### ğŸ’½ SSD Nearly Full  
![SSD usage](girigiriSSD.png)

### ğŸ§  RAM Near Capacity  
![Memory usage](memorigirigiri.png)

### ğŸ–¥ System Specs  
![System info](spec.png)

---

## ğŸš¨ Execution Attempt Log

```powershell
ollama run gpt-oss:20b

ğŸ“œ Why This Matters
In a world where most LLMs depend on the cloud,
this attempt proves that a laptop with modest specs, limited storage, and no network
can still fight to host a massive model like a 20B LLM â€” locally.

Itâ€™s not about winning. Itâ€™s about proving it can be tried.
Itâ€™s about reminding ourselves:

"You donâ€™t need perfect conditions to try impossible things."

âœï¸ Notes
Model loading partially succeeded

RAM limit likely triggered runtime crash (exit status 2)

Execution was monitored with no other major processes running

This was done intentionally without freeing space, to prove the threshold

ğŸ§  Authored by
KGNINJA
https://x.com/FuwaCocoOwnerKG

â€œI chose a machine not because it was strong,
but because it would make the story stronger.â€

ğŸ· Tags
#OfflineLLM #20Bboot #LimitBreak #KGNINJA
